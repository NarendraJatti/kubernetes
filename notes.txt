https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/annotations/

Ingress controller=LB +APIGW

The kubelet is a critical component of Kubernetes that runs on every node in a Kubernetes cluster. Its main role is to manage the state of the node by interacting with the control plane components and ensuring that containers (pods) are running as expected.

Here are the key responsibilities of the kubelet:

Pod Management: The kubelet monitors pod specifications sent by the control plane (API server) and ensures that containers defined in the pod are running on the node.

Container Management: It communicates with the container runtime (e.g., Docker, containerd) to start, stop, and manage the lifecycle of containers.

Health Monitoring: The kubelet regularly checks the health of running pods and containers. It restarts containers if they crash or fail, based on the configuration (such as liveness and readiness probes).

Node Registration: The kubelet registers the node with the Kubernetes control plane and reports the node’s status, including resource usage (CPU, memory, etc.) and conditions (e.g., DiskPressure, MemoryPressure).

Resource Management: The kubelet enforces resource limits (CPU, memory) for containers, ensuring that the allocated resources are respected.

Volume Management: The kubelet manages pod volumes, ensuring that the necessary storage resources are mounted into the pod’s containers.

Node Labels and Taints: The kubelet applies and manages node labels and taints that affect pod scheduling decisions.

Log Collection: It can be configured to collect and forward logs from containers to the centralized logging system.

The kubelet does not manage containers directly. It works with the container runtime on the node to handle container operations.

==========

Kube-proxy is an essential component in Kubernetes that handles the networking between services and pods. One of its primary responsibilities is ensuring that traffic destined for a Kubernetes Service is routed to the correct backend pod(s). To do this, it manages network rules, and one of the ways it achieves this is by updating iptables.

cat crash-app.sh 
kubectl exec --namespace=kube-public curl -- wget -qO- http://webapp-service.default.svc.cluster.local:8080/crash

 cat curl-test.sh 
for i in {1..20}; do
   kubectl exec --namespace=kube-public curl -- sh -c 'test=`wget -qO- -T 2  http://webapp-service.default.svc.cluster.local:8080/ready 2>&1` && echo "$test OK" || echo "Failed"';
   echo ""
done

Here are a few common scenarios to delete an object and apply it again for changes to take effect:

Modifying the value of an existing label selector
Changing volume specifications
Applying changes to certain controllers
Changing service selectors
Changing resource constraints of a pod


A CreateContainerError in Kubernetes typically occurs during the process

Incorrect image specification
Runtime error
Insufficient resources
Missing mounted object

A. ClusterRoleBindings cannot reference Roles.
Correct. ClusterRoleBindings are intended to bind ClusterRoles, not Roles. ClusterRoles are designed to grant permissions across the entire cluster or multiple namespaces, whereas Roles are namespace-specific.

B. Creating the RoleBinding in a namespace other than the subjects’ allows the subject to have roles in other namespaces.
Correct. When a RoleBinding is created in a namespace other than where the subjects are, it enables the subjects to have roles in namespaces other than their own.

C. Adding the namespace under the roleRef in a RoleBinding allows binding subjects to roles in other namespaces.
Incorrect. The roleRef in a RoleBinding does not allow for a namespace specification because RoleBindings cannot reference Roles outside their own namespace.

D. RoleBindings and ServiceAccounts must exist in the same namespace.
Incorrect. RoleBindings can be created in any namespace and can reference ServiceAccounts from any namespace.

E. RoleBindings connect ClusterRoles, but they only give access to the namespace defined in the binding.
Correct. RoleBindings connect ClusterRoles to subjects (users or service accounts), but they only grant access within the namespace specified in the binding, ensuring access control boundaries.

A Network Policy is a namespaced resource.
Network Policy can target pods not services.

The correct answer is ReadWriteMany (RWX) because this access mode allows multiple Pods on different nodes to read and write to the same volume. 'ReadWriteOnce (RWO)' allows read/write access by a single node, and 'ReadOnlyMany (ROX)' allows multiple nodes to read but not write.


A PVC can remain in the Pending state for several reasons. The requested storage class might not exist, meaning there is no provisioner available to create the PV. The access mode requested by the PVC might not match any available PV, making it impossible to bind. Additionally, the available PVs might have insufficient capacity to meet the PVC's request. Therefore, all these factors need to be considered when troubleshooting a PVC in the Pending state.

Identify workload waste and remove it safely 
Pinpoint and remediate issues causing latency and service disruption (OOM, CPU Throttling, Evictions)
Evaluate the efficiency of Horizontal and Node Austoscalers (HPA, KEDA, Karpenter, Cluster Autoscaler)
Select proper Node types based on utilization trends

A Kubernetes Service provides a stable network endpoint for a set of Pods. It acts as an abstraction layer over the Pods and ensures that communication with the application is consistent, even when the underlying Pods are replaced or rescheduled.
Types of Services:
ClusterIP: Exposes the service internally within the cluster.
NodePort: Exposes the service on each Node’s IP at a static port.
LoadBalancer: Exposes the service externally using a cloud provider's load balancer.
ExternalName: Maps the service to a DNS name
An Istio VirtualService is an abstraction provided by the Istio service mesh that allows advanced traffic management and routing within the mesh. It operates at a higher layer (Layer 7) than the Kubernetes Service (Layer 4), giving finer control over HTTP, gRPC, WebSocket, and TCP traffic.


We have now configured an authorization policy to allow all GET requests from the demo-app namespace to the demo-api namespace. This means that any GET requests from any other namespace like default will be rejected. Lets try it out.

There is an nginx deployment and service running under demo-api namespace. Identify the cluster IP of the service and carry out some tests.

There is a curl pod running under the default and the demo-app namespaces. Identify the pod names and let's try to curl the nginx service (running under demo-api namespace) from both pods one by one to see the results. Use the below commands:

a. kubectl exec <pod-name>  -c curl  -- curl -s <nginx-service-cluster-ip>

b. kube
ctl exec <pod-name> -n demo-app -c curl -- curl -s <nginx-service-cluster-ip>

Expected Results

In Kubernetes, eBPF (extended Berkeley Packet Filter) has an important relationship with pods because eBPF programs can be used to monitor, secure, and manage network traffic and system behavior in pods, all while maintaining high performance
eBPF working along with vpc cni attaching network policies for the pods
Role of eBPF: eBPF can inspect and manipulate network traffic before it reaches the pod, allowing enforcement of Kubernetes NetworkPolicies without relying on traditional methods like iptables.
eBPF can be used to:
Enforce network security policies.
Perform packet filtering.
Monitor traffic flows across pods and services.
Provide visibility into network traffic at a granular level (L3/L4/L7).

iptables is a tool used to configure Linux kernel firewall rules, and it plays a significant role in Docker and Kubernetes networking.

eBPF vs. iptables in Kubernetes:
iptables: Traditional approach, used for years, but can have performance limitations due to the large number of rules that can accumulate in complex Kubernetes environments.
eBPF: Newer, more efficient, and flexible approach. Tools like Cilium are replacing iptables with eBPF for tasks like routing, load balancing, and enforcing network policies because of its ability to execute directly in the kernel, reducing overhead and improving scalability.

storage in eks:
aws ebs csi driver
k get storageclasses

eks secret  store,csi secret store driver
 vault,aws secret store,parameter store

 Internally, Kubernetes uses kube-proxy to route the traffic from the worker node's port to the appropriate pod based on load balancing algorithms (like round-robin).
 Key Differences:
NodePort: You expose a specific port on each node and directly access nodes.
LoadBalancer: Cloud provider’s load balancer abstracts away the nodes, and traffic is routed to the service’s public IP. Internally, the load balancer uses the NodePort to send traffic to the node, which kube-proxy handles and forwards to the pods.


Karpenter
===============
pending unscheduleable pods.
A PodDisruptionBudget (PDB) in Kubernetes is a policy that ensures a minimum number of pods are always available during voluntary disruptions, like node draining for maintenance, rolling updates, or cluster scaling
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: my-pdb
spec:
  minAvailable: 2  # At least 2 pods must always be available
  selector:
    matchLabels:
      app: my-app  # The PDB will apply to pods with this label
